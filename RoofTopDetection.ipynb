{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_UISOa4YMLH",
        "outputId": "68f4c9b4-5445-4b79-b53f-74399d7aef87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.116-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.14)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.7)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.116-py3-none-any.whl (984 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m984.0/984.0 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.116 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python pillow numpy matplotlib torch ultralytics ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L16xKeOgYRTg",
        "outputId": "72ff6ae6-24d8-4e1d-c52b-c7fcebb0489e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import PIL\n",
        "import glob\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4KWgcI1YWmR"
      },
      "outputs": [],
      "source": [
        "PIL.Image.MAX_IMAGE_PIXELS = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TenIE0dtYXBk",
        "outputId": "1b0aa122-6150-474d-c758-3634ba42f13a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5VJLb8mYZJY"
      },
      "outputs": [],
      "source": [
        "# Main folder where all your data will be stored\n",
        "main_folder = \"/content/drive/MyDrive/Project\"  # MODIFY THIS PATH\n",
        "\n",
        "# Directory for temporary files\n",
        "temp_folder = os.path.join(main_folder, \"temp\")\n",
        "\n",
        "# Output directory for predicted images\n",
        "output_dir = os.path.join(main_folder, \"predictions\")\n",
        "\n",
        "# Path where your trained model will be saved/loaded\n",
        "model_path = os.path.join(main_folder, \"models/best_rooftop.pt\")\n",
        "\n",
        "# Path to your YOLOv8 data.yaml file that defines your dataset\n",
        "data_yaml_path = os.path.join('/content/drive/MyDrive/rooftop_dataset/data.yaml')\n",
        " # MODIFY THIS WITH YOUR DATA.YAML PATH\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(temp_folder, exist_ok=True)\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybSkFFigYff9"
      },
      "outputs": [],
      "source": [
        "def cleanup_temp_files():\n",
        "    \"\"\"Remove all files in the temporary directory\"\"\"\n",
        "    for file in os.listdir(temp_folder):\n",
        "        file_path = os.path.join(temp_folder, file)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file_path}: {e}\")\n",
        "    print(\"Temporary files cleaned up\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMJbZReeYiXA"
      },
      "outputs": [],
      "source": [
        "def split_image_into_tiles(image, output_folder, tile_size=1024):\n",
        "    \"\"\"\n",
        "    Split a large image into smaller tiles for processing\n",
        "\n",
        "    Args:\n",
        "        image: PIL Image object or path to image\n",
        "        output_folder: Folder to save the tiles\n",
        "        tile_size: Size of each tile (default: 1024x1024)\n",
        "\n",
        "    Returns:\n",
        "        tuple: (number of tiles, number of rows, number of columns)\n",
        "    \"\"\"\n",
        "    # Clean up any existing tiles\n",
        "    cleanup_temp_files()\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Open the image if it's a path\n",
        "    if isinstance(image, str):\n",
        "        image = Image.open(image)\n",
        "\n",
        "    width, height = image.size\n",
        "\n",
        "    # Calculate grid dimensions\n",
        "    num_cols = (width + tile_size - 1) // tile_size\n",
        "    num_rows = (height + tile_size - 1) // tile_size\n",
        "\n",
        "    # Count for naming the tiles\n",
        "    tile_count = 1\n",
        "\n",
        "    # Process the image in tiles\n",
        "    for y in range(0, height, tile_size):\n",
        "        for x in range(0, width, tile_size):\n",
        "            # Define boundaries\n",
        "            right = min(x + tile_size, width)\n",
        "            bottom = min(y + tile_size, height)\n",
        "\n",
        "            # Extract tile\n",
        "            tile = image.crop((x, y, right, bottom))\n",
        "\n",
        "            # If the tile is smaller than tile_size, pad it\n",
        "            if tile.size[0] < tile_size or tile.size[1] < tile_size:\n",
        "                new_tile = Image.new(image.mode, (tile_size, tile_size))\n",
        "                new_tile.paste(tile, (0, 0))\n",
        "                tile = new_tile\n",
        "\n",
        "            # Save the tile\n",
        "            output_path = os.path.join(output_folder, f\"{tile_count}.jpg\")\n",
        "            tile.save(output_path, quality=95)\n",
        "\n",
        "            tile_count += 1\n",
        "\n",
        "    return tile_count - 1, num_rows, num_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jivSM3BZYmd2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_rooftop_model(data_yaml, epochs=50, imgsz=640):\n",
        "    \"\"\"\n",
        "    Train a YOLOv8 model on rooftop data\n",
        "\n",
        "    Args:\n",
        "        data_yaml: Path to the YAML file defining the dataset\n",
        "        epochs: Number of training epochs\n",
        "        imgsz: Input image size for training\n",
        "\n",
        "    Returns:\n",
        "        Trained model\n",
        "    \"\"\"\n",
        "    print(f\"Training model with {data_yaml} for {epochs} epochs...\")\n",
        "\n",
        "    # Initialize model with YOLOv8 segmentation model (pretrained)\n",
        "    model = YOLO('yolov8s-seg.pt')\n",
        "\n",
        "    # Train the model (fine-tune on your data)\n",
        "    results = model.train(\n",
        "        data=data_yaml,\n",
        "        epochs=epochs,\n",
        "        imgsz=imgsz,\n",
        "        patience=15,  # Early stopping patience\n",
        "        batch=16,     # Batch size (adjust based on available memory)\n",
        "        save=True     # Save best model\n",
        "    )\n",
        "\n",
        "    # Copy the best model to our specified path\n",
        "    best_model_path = os.path.join(model.trainer.save_dir, 'weights/best.pt')\n",
        "    if os.path.exists(best_model_path):\n",
        "        import shutil\n",
        "        shutil.copy(best_model_path, model_path)\n",
        "        print(f\"Best model saved to {model_path}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAM-Bi-gYtUA"
      },
      "outputs": [],
      "source": [
        "def predict_rooftops_in_tiles(model, tiles_folder, output_folder, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Predict rooftops in all tiles and save B&W masks\n",
        "\n",
        "    Args:\n",
        "        model: Loaded YOLO model\n",
        "        tiles_folder: Folder containing image tiles\n",
        "        output_folder: Folder to save mask outputs\n",
        "        conf_threshold: Confidence threshold for predictions\n",
        "    \"\"\"\n",
        "    # Get all JPG images in the tiles folder\n",
        "    image_files = [\n",
        "        f for f in os.listdir(tiles_folder)\n",
        "        if os.path.isfile(os.path.join(tiles_folder, f))\n",
        "        and f.lower().endswith('.jpg')\n",
        "    ]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        # Load image\n",
        "        img_path = os.path.join(tiles_folder, image_file)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"Could not read image: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img_height, img_width = img.shape[:2]\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(\n",
        "            source=img,\n",
        "            save=False,\n",
        "            save_txt=False,\n",
        "            stream=False,\n",
        "            conf=conf_threshold,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Create a blank mask image\n",
        "        mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
        "\n",
        "        # Process results\n",
        "        if results[0].masks is not None:\n",
        "            # Get masks for rooftops (class 0)\n",
        "            for i, box in enumerate(results[0].boxes):\n",
        "                if int(box.cls.item()) == 0:  # Check if the class is rooftop (class 0)\n",
        "                    mask_segment = results[0].masks.data[i].cpu().numpy()\n",
        "                    mask_segment = cv2.resize(mask_segment.astype(np.uint8), (img_width, img_height))\n",
        "                    mask = np.logical_or(mask, mask_segment).astype(np.uint8) * 255\n",
        "\n",
        "        # Save the binary mask\n",
        "        output_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_mask.jpg\")\n",
        "        cv2.imwrite(output_path, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eZZGy-6b6sR"
      },
      "outputs": [],
      "source": [
        "def merge_masks(tiles_folder, output_path, num_rows, num_cols, original_size=None):\n",
        "    \"\"\"\n",
        "    Merge multiple mask tiles back into a single large image\n",
        "\n",
        "    Args:\n",
        "        tiles_folder: Folder containing the mask tiles\n",
        "        output_path: Path to save the merged mask\n",
        "        num_rows: Number of rows in the grid\n",
        "        num_cols: Number of columns in the grid\n",
        "        original_size: Original image size (width, height) to crop to\n",
        "\n",
        "    Returns:\n",
        "        PIL Image of the merged mask\n",
        "    \"\"\"\n",
        "    # Sort images by filename\n",
        "    mask_files = sorted(\n",
        "        [f for f in os.listdir(tiles_folder) if f.endswith('_mask.jpg')],\n",
        "        key=lambda x: int(os.path.splitext(x.split('_')[0])[0])\n",
        "    )\n",
        "\n",
        "    # Load the first image to get dimensions\n",
        "    first_image = Image.open(os.path.join(tiles_folder, mask_files[0]))\n",
        "    tile_width, tile_height = first_image.size\n",
        "\n",
        "    # Create a blank canvas for the merged image\n",
        "    merged_width = num_cols * tile_width\n",
        "    merged_height = num_rows * tile_height\n",
        "    merged_image = Image.new('L', (merged_width, merged_height), 0)\n",
        "\n",
        "    # Place each tile in the correct position\n",
        "    for idx, file in enumerate(mask_files):\n",
        "        if idx >= num_rows * num_cols:\n",
        "            break\n",
        "\n",
        "        row = idx // num_cols\n",
        "        col = idx % num_cols\n",
        "\n",
        "        tile = Image.open(os.path.join(tiles_folder, file))\n",
        "        merged_image.paste(tile, (col * tile_width, row * tile_height))\n",
        "\n",
        "    # Crop to original size if specified\n",
        "    if original_size:\n",
        "        merged_image = merged_image.crop((0, 0, original_size[0], original_size[1]))\n",
        "\n",
        "    # Save the merged image\n",
        "    merged_image.save(output_path)\n",
        "    return merged_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz4ByNqrb9B7"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, data_yaml):\n",
        "    \"\"\"\n",
        "    Evaluate model performance on validation data\n",
        "\n",
        "    Args:\n",
        "        model: Loaded YOLO model\n",
        "        data_yaml: Path to the data YAML file\n",
        "\n",
        "    Returns:\n",
        "        Metrics from validation\n",
        "    \"\"\"\n",
        "    print(f\"Evaluating model performance...\")\n",
        "\n",
        "    # Validate the model\n",
        "    metrics = model.val(data=data_yaml)\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"\\n--- Model Evaluation Metrics ---\")\n",
        "    print(f\"Bounding Box mAP50: {metrics.box.map50:.4f}\")\n",
        "    print(f\"Bounding Box mAP50-95: {metrics.box.map:.4f}\")\n",
        "    print(f\"Segmentation Mask mAP50: {metrics.seg.map50:.4f}\")\n",
        "    print(f\"Segmentation Mask mAP50-95: {metrics.seg.map:.4f}\")\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54hmqVLQcBlS"
      },
      "outputs": [],
      "source": [
        "def process_uploaded_image(model_path, conf_threshold=0.25):\n",
        "    \"\"\"\n",
        "    Process a user-uploaded image to detect rooftops\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to the trained model\n",
        "        conf_threshold: Confidence threshold for predictions\n",
        "\n",
        "    Returns:\n",
        "        Paths to the output files\n",
        "    \"\"\"\n",
        "    # Load the model\n",
        "    print(\"Loading model...\")\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Clean up any existing temporary files\n",
        "    cleanup_temp_files()\n",
        "\n",
        "    # Upload image\n",
        "    print(\"Please upload a JPG image:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No image uploaded.\")\n",
        "        return None\n",
        "\n",
        "    # Get the first uploaded file\n",
        "    image_filename = list(uploaded.keys())[0]\n",
        "    image_path = os.path.join(temp_folder, image_filename)\n",
        "\n",
        "    # Save the uploaded file\n",
        "    with open(image_path, 'wb') as f:\n",
        "        f.write(uploaded[image_filename])\n",
        "\n",
        "    # Load the image\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        original_width, original_height = image.size\n",
        "        print(f\"Image loaded: {image_filename} ({original_width}x{original_height})\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None\n",
        "\n",
        "    # For small images, process directly\n",
        "    if original_width <= 1024 and original_height <= 1024:\n",
        "        print(\"Processing small image directly...\")\n",
        "\n",
        "        # Convert to OpenCV format\n",
        "        img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(\n",
        "            source=img_cv,\n",
        "            save=False,\n",
        "            save_txt=False,\n",
        "            stream=False,\n",
        "            conf=conf_threshold,\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Create a blank mask image\n",
        "        mask = np.zeros((original_height, original_width), dtype=np.uint8)\n",
        "\n",
        "        # Process results\n",
        "        if results[0].masks is not None:\n",
        "            for i, box in enumerate(results[0].boxes):\n",
        "                if int(box.cls.item()) == 0:  # Check if the class is rooftop (class 0)\n",
        "                    mask_segment = results[0].masks.data[i].cpu().numpy()\n",
        "                    mask_segment = cv2.resize(mask_segment.astype(np.uint8), (original_width, original_height))\n",
        "                    mask = np.logical_or(mask, mask_segment).astype(np.uint8) * 255\n",
        "\n",
        "        # Save outputs\n",
        "        mask_path = os.path.join(output_dir, f\"{os.path.splitext(image_filename)[0]}_mask.jpg\")\n",
        "        cv2.imwrite(mask_path, mask)\n",
        "\n",
        "        # Create visualization\n",
        "        colored_mask = np.zeros((original_height, original_width, 3), dtype=np.uint8)\n",
        "        colored_mask[mask > 0] = [0, 0, 255]  # Red for rooftops\n",
        "\n",
        "        # Overlay the mask on the original image\n",
        "        overlay_img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "        alpha = 0.5\n",
        "        overlay = cv2.addWeighted(overlay_img, 1, colored_mask, alpha, 0)\n",
        "\n",
        "        overlay_path = os.path.join(output_dir, f\"{os.path.splitext(image_filename)[0]}_overlay.jpg\")\n",
        "        cv2.imwrite(overlay_path, overlay)\n",
        "\n",
        "    else:\n",
        "        # For large images, split into tiles\n",
        "        print(\"Splitting large image into tiles...\")\n",
        "        num_tiles, num_rows, num_cols = split_image_into_tiles(image, temp_folder)\n",
        "        print(f\"Image split into {num_tiles} tiles ({num_rows}x{num_cols})\")\n",
        "\n",
        "        # Process tiles\n",
        "        print(\"Processing tiles...\")\n",
        "        predict_rooftops_in_tiles(model, temp_folder, temp_folder, conf_threshold)\n",
        "\n",
        "        # Merge tiles\n",
        "        print(\"Merging masks...\")\n",
        "        mask_path = os.path.join(output_dir, f\"{os.path.splitext(image_filename)[0]}_mask.jpg\")\n",
        "        merged_mask = merge_masks(temp_folder, mask_path, num_rows, num_cols, (original_width, original_height))\n",
        "\n",
        "        # Create visualization\n",
        "        print(\"Creating visualization...\")\n",
        "        mask = np.array(merged_mask)\n",
        "        colored_mask = np.zeros((original_height, original_width, 3), dtype=np.uint8)\n",
        "        colored_mask[mask > 0] = [0, 0, 255]  # Red for rooftops\n",
        "\n",
        "        # Overlay the mask on the original image\n",
        "        overlay_img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "        alpha = 0.5\n",
        "        overlay = cv2.addWeighted(overlay_img, 1, colored_mask, alpha, 0)\n",
        "\n",
        "        overlay_path = os.path.join(output_dir, f\"{os.path.splitext(image_filename)[0]}_overlay.jpg\")\n",
        "        cv2.imwrite(overlay_path, overlay)\n",
        "\n",
        "    # Clean up temporary files\n",
        "    cleanup_temp_files()\n",
        "\n",
        "    # Display results\n",
        "    print(\"Displaying results...\")\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title('Binary Rooftop Mask')\n",
        "    plt.axis('off')\n",
        "    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    plt.imshow(mask_img, cmap='gray')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title('Overlay Visualization')\n",
        "    plt.axis('off')\n",
        "    overlay_img = cv2.imread(overlay_path)\n",
        "    overlay_img = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(overlay_img)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Results saved to {output_dir}\")\n",
        "    return mask_path, overlay_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4DVHBjYcElN"
      },
      "outputs": [],
      "source": [
        "# Create interactive widgets for model training\n",
        "def create_training_widgets():\n",
        "    \"\"\"Create and display widgets for model training\"\"\"\n",
        "    epochs_slider = widgets.IntSlider(\n",
        "        value=50, min=10, max=100, step=10,\n",
        "        description='Epochs:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    imgsz_slider = widgets.IntSlider(\n",
        "        value=640, min=320, max=1280, step=64,\n",
        "        description='Image Size:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    train_button = widgets.Button(\n",
        "        description='Train Model',\n",
        "        button_style='primary',\n",
        "        tooltip='Click to start training'\n",
        "    )\n",
        "\n",
        "    output = widgets.Output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kTRfDErcGQ1"
      },
      "outputs": [],
      "source": [
        "train_button = widgets.Button(description=\"Train Model\")\n",
        "\n",
        "def on_predict_button_clicked(b):\n",
        "        with output:\n",
        "            process_uploaded_image(model_path, conf_threshold=conf_slider.value)\n",
        "\n",
        "predict_button.on_click(on_predict_button_clicked)\n",
        "\n",
        "    # Display widgets\n",
        "display(widgets.VBox([widgets.HTML(value=\"<h3>Rooftop Detection:</h3>\"),conf_slider,predict_button,output]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O_xdC9OpfJv0",
        "outputId": "42fc060c-55c4-46dd-9ead-292df115dbc6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/FinalProject/models/best_rooftop.pt'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hkoTN39cIXG"
      },
      "outputs": [],
      "source": [
        "def create_prediction_widgets():\n",
        "    \"\"\"Create and display widgets for rooftop prediction\"\"\"\n",
        "    conf_slider = widgets.FloatSlider(\n",
        "        value=0.25, min=0.05, max=0.95, step=0.05,\n",
        "        description='Confidence:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    predict_button = widgets.Button(\n",
        "        description='Detect Rooftops',\n",
        "        button_style='success',\n",
        "        tooltip='Click to upload an image and detect rooftops'\n",
        "    )\n",
        "\n",
        "    output = widgets.Output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "2bc560190e0649e4b245b61e0e124100",
            "75515c9a4e794062b75faa289af3b075",
            "9041dac2e0e6425ca5c3621500a46bce",
            "575abbeeeba34c8598719b54949541a7",
            "851ca58bfef44c419717698439fb59fc",
            "dcb73f040aa445b79b57dbd89876f6b1",
            "c99e89e191b04411b9c4c9d5b0c38f6d",
            "95622a92b71b453ca20ae4808fbb5e66",
            "0201c8d3b2f04b329c0da1c0e239da3b",
            "b2e02833611f4b1291aa2c7c8043a3ab",
            "a29bb2db37354836b22174acf380b35f",
            "f854dacab20d4caa8bcd8bd37fd2f2d5",
            "158b131f247349249fb90b61be6186c0"
          ]
        },
        "id": "v3PdEtgRcLYy",
        "outputId": "1f99980b-b08b-422e-a9f8-0f1dd897d08d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bc560190e0649e4b245b61e0e124100",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<h3>Rooftop Detection:</h3>'), FloatSlider(value=0.5, continuous_update=False, desc…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Create the button\n",
        "predict_button = widgets.Button(\n",
        "    description='Predict',\n",
        "    button_style='success',  # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click to run prediction',\n",
        "    icon='check'  # Optional\n",
        ")\n",
        "\n",
        "# Create other UI components (example: confidence slider)\n",
        "conf_slider = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0.1,\n",
        "    max=1.0,\n",
        "    step=0.05,\n",
        "    description='Confidence:',\n",
        "    continuous_update=False\n",
        ")\n",
        "\n",
        "# Output widget to show results\n",
        "output = widgets.Output()\n",
        "\n",
        "# Define what happens when button is clicked\n",
        "def on_predict_button_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        process_uploaded_image(model_path, conf_threshold=conf_slider.value)\n",
        "\n",
        "# Connect the click event\n",
        "predict_button.on_click(on_predict_button_clicked)\n",
        "\n",
        "# Display all widgets together\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(value=\"<h3>Rooftop Detection:</h3>\"),\n",
        "    conf_slider,\n",
        "    predict_button,\n",
        "    output\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "KFhkk8WIcNYo",
        "outputId": "6df8570e-7fc2-4a50-cbcb-4f90c10c8993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Rooftop Detection with YOLOv8\n",
            "This notebook detects rooftops in any JPG image.\n",
            "You can train the model with your own data or use a pre-trained model.\n"
          ]
        }
      ],
      "source": [
        "print(\"# Rooftop Detection with YOLOv8\")\n",
        "print(\"This notebook detects rooftops in any JPG image.\")\n",
        "print(\"You can train the model with your own data or use a pre-trained model.\")\n",
        "\n",
        "# Create training widgets\n",
        "create_training_widgets()\n",
        "\n",
        "# Create prediction widgets\n",
        "create_prediction_widgets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIgvVJDciiem",
        "outputId": "0fae21b2-d290-451a-ad80-bb1d5c9cb942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model with /content/drive/MyDrive/rooftop_dataset/data.yaml for 50 epochs...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-seg.pt to 'yolov8s-seg.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22.8M/22.8M [00:00<00:00, 222MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.116 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.pt, data=/content/drive/MyDrive/rooftop_dataset/data.yaml, epochs=50, time=None, patience=15, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 20.8MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n",
            "YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients, 42.7 GFLOPs\n",
            "\n",
            "Transferred 411/417 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 85.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.4±0.1 ms, read: 13.6±4.9 MB/s, size: 66.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/rooftop_dataset/train/labels... 2100 images, 71 backgrounds, 0 corrupt: 100%|██████████| 2100/2100 [00:31<00:00, 66.54it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/rooftop_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.4±0.2 ms, read: 8.9±5.3 MB/s, size: 68.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/rooftop_dataset/valid/labels... 105 images, 1 backgrounds, 0 corrupt: 100%|██████████| 105/105 [00:01<00:00, 68.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/rooftop_dataset/valid/labels.cache\n",
            "Plotting labels to runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/segment/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      5.36G      1.476      2.744      1.367      1.357        172        640: 100%|██████████| 132/132 [01:59<00:00,  1.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.789      0.766      0.819      0.584      0.768      0.754      0.782      0.473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50      6.59G      1.336      2.433      1.025      1.253         63        640: 100%|██████████| 132/132 [01:52<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.687      0.649      0.699      0.476      0.682       0.63      0.665      0.389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50      6.63G      1.329      2.409      1.032      1.244         95        640: 100%|██████████| 132/132 [01:51<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.809      0.745      0.824      0.614      0.822      0.734      0.821      0.556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50      6.67G      1.304      2.345     0.9882      1.229        196        640: 100%|██████████| 132/132 [01:51<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.835       0.77      0.845      0.615      0.834      0.771      0.841      0.553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50      6.71G      1.252      2.259     0.9107      1.208         79        640: 100%|██████████| 132/132 [01:52<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.844      0.769      0.847      0.632      0.843      0.764      0.838      0.555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      6.75G      1.209      2.196     0.8869      1.185        143        640: 100%|██████████| 132/132 [01:53<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.843      0.778       0.86      0.657      0.844      0.783      0.857      0.591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50      6.79G      1.192      2.134     0.8578      1.177         80        640: 100%|██████████| 132/132 [01:52<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026       0.84       0.82      0.875      0.669       0.85      0.814      0.874       0.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50      6.83G      1.168      2.109     0.8319       1.16         61        640: 100%|██████████| 132/132 [01:52<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026       0.86      0.839      0.895      0.698      0.875      0.816      0.887      0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50      6.87G      1.143      2.063     0.8118       1.15         77        640: 100%|██████████| 132/132 [01:52<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.833      0.832      0.877      0.671      0.838      0.824      0.871      0.622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50      6.91G      1.131      2.037     0.7989      1.142         84        640: 100%|██████████| 132/132 [01:52<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.866      0.791      0.879      0.685      0.865      0.789      0.871      0.629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50      6.95G      1.134      2.024     0.7863      1.142        187        640: 100%|██████████| 132/132 [01:52<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.871      0.836      0.897      0.704      0.871      0.833       0.89      0.642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50      6.99G      1.119       2.01     0.7658      1.131         66        640: 100%|██████████| 132/132 [01:53<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.856      0.848        0.9      0.708      0.854      0.849      0.897      0.663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50      7.03G        1.1      1.968     0.7495      1.121         97        640: 100%|██████████| 132/132 [01:53<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026       0.88      0.826      0.901      0.718       0.88      0.828      0.901      0.664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50      7.07G      1.084      1.932     0.7344      1.112        118        640: 100%|██████████| 132/132 [01:50<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.869      0.834      0.901      0.718       0.87      0.834      0.896      0.664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50      7.11G      1.092      1.921     0.7356      1.115        121        640: 100%|██████████| 132/132 [01:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.864      0.846        0.9      0.717       0.86      0.852      0.897      0.659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50      7.15G      1.058      1.881     0.7104      1.098         99        640: 100%|██████████| 132/132 [01:52<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.892      0.836      0.908      0.729      0.892      0.836      0.906      0.675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50      7.19G      1.062      1.916     0.7161      1.104        125        640: 100%|██████████| 132/132 [01:53<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026       0.88      0.869      0.914      0.741      0.881       0.87      0.912      0.689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50      7.23G      1.046      1.858     0.6935       1.09        138        640: 100%|██████████| 132/132 [01:50<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.872      0.847      0.909      0.727      0.871      0.849      0.905      0.681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50      7.27G      1.037      1.842     0.6926       1.09        127        640: 100%|██████████| 132/132 [01:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.889      0.843      0.911      0.736       0.88      0.849      0.909      0.689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50      7.31G      1.022      1.825     0.6745      1.087        101        640: 100%|██████████| 132/132 [01:49<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.876      0.845       0.91      0.734      0.874      0.843      0.906      0.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50      7.35G       1.02      1.811     0.6744      1.078        179        640: 100%|██████████| 132/132 [01:50<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.891      0.853      0.912      0.732      0.889      0.851      0.907      0.678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      7.39G      1.006      1.783     0.6578      1.073        133        640: 100%|██████████| 132/132 [01:51<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.874      0.866      0.922      0.745      0.873      0.867      0.918      0.689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/50      5.73G      1.013      1.798     0.6655      1.078         87        640: 100%|██████████| 132/132 [01:50<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.876      0.846      0.914      0.733      0.875      0.844       0.91      0.685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/50      6.92G     0.9988      1.779     0.6509      1.069         97        640: 100%|██████████| 132/132 [01:52<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.877      0.866      0.923      0.754       0.88      0.864      0.917      0.701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/50      6.92G     0.9981      1.783      0.651      1.068        125        640: 100%|██████████| 132/132 [01:49<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026       0.89      0.871      0.928       0.76      0.889      0.871      0.925      0.708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/50      6.92G     0.9752       1.73     0.6345      1.058         56        640: 100%|██████████| 132/132 [01:49<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.907      0.862      0.926      0.762      0.902      0.868      0.924      0.713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/50      6.92G     0.9637      1.701     0.6205      1.051         91        640: 100%|██████████| 132/132 [01:49<00:00,  1.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.894      0.863      0.923      0.752      0.893      0.862      0.918      0.695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/50      6.92G     0.9701      1.713      0.616      1.058         59        640: 100%|██████████| 132/132 [01:51<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.883      0.863      0.923       0.76      0.883      0.863       0.92       0.72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/50      6.92G     0.9616      1.696     0.6108      1.051        148        640: 100%|██████████| 132/132 [01:52<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.883      0.872      0.924      0.763      0.882      0.872      0.922      0.712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/50      6.92G      0.956      1.677     0.6044      1.045        113        640: 100%|██████████| 132/132 [01:53<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.896      0.875       0.93      0.761      0.896      0.875      0.926      0.715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      31/50      6.92G     0.9508      1.678     0.6056      1.045        103        640: 100%|██████████| 132/132 [01:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.901      0.873      0.929      0.763      0.904      0.872      0.928       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      32/50      6.92G     0.9497      1.663     0.5953      1.042         83        640: 100%|██████████| 132/132 [01:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.888      0.886      0.931      0.777      0.892      0.885      0.929      0.727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      33/50      6.92G     0.9443      1.658     0.5899      1.038        100        640: 100%|██████████| 132/132 [01:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.906      0.868       0.93      0.765      0.912      0.865      0.929      0.721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      34/50      6.96G     0.9181      1.608     0.5771      1.026         73        640: 100%|██████████| 132/132 [01:47<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.904       0.87      0.933      0.775      0.916      0.865      0.931      0.719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      35/50         7G     0.9316       1.63     0.5789      1.034        205        640: 100%|██████████| 132/132 [01:51<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.906      0.853      0.929       0.77      0.907      0.848      0.923      0.711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      36/50      7.04G     0.9125      1.604     0.5691      1.024         94        640: 100%|██████████| 132/132 [01:50<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.904      0.884      0.937      0.778      0.902      0.882      0.931      0.719\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      37/50      7.08G     0.9154      1.612     0.5668      1.025        124        640: 100%|██████████| 132/132 [01:49<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.909       0.88      0.936      0.781      0.908      0.879      0.935      0.733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      38/50      7.12G     0.8998      1.576     0.5609      1.018         64        640: 100%|██████████| 132/132 [01:51<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.33it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.902      0.891      0.938      0.783      0.903      0.889      0.933      0.735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      39/50      7.16G     0.9041      1.591     0.5555      1.021        107        640: 100%|██████████| 132/132 [01:50<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.896      0.885      0.934      0.778      0.899      0.876      0.931      0.729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      40/50       7.2G     0.8964      1.581     0.5545      1.019         61        640: 100%|██████████| 132/132 [01:49<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:04<00:00,  1.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.922       0.87      0.938      0.784       0.92      0.868      0.933      0.724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      41/50      7.24G     0.8899      1.584     0.5154      1.026         62        640: 100%|██████████| 132/132 [01:07<00:00,  1.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.889      0.879      0.936      0.779      0.892       0.88      0.934      0.734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      42/50      7.28G     0.8702      1.545     0.5026      1.019         72        640: 100%|██████████| 132/132 [01:02<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026       0.91      0.873      0.937      0.788      0.896      0.884      0.936      0.738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      43/50      7.32G     0.8535      1.524     0.4907      1.014         48        640: 100%|██████████| 132/132 [01:02<00:00,  2.10it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.909      0.882      0.941       0.79      0.905      0.877      0.935      0.738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      44/50      7.36G      0.847      1.513     0.4868      1.009         65        640: 100%|██████████| 132/132 [01:04<00:00,  2.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.903      0.893      0.942      0.789      0.903      0.887      0.937       0.74\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      45/50       7.4G     0.8416      1.499      0.478      1.004         57        640: 100%|██████████| 132/132 [01:03<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.909       0.88      0.941      0.793      0.909       0.88      0.938      0.742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      46/50      5.38G     0.8333      1.483     0.4729      1.005         67        640: 100%|██████████| 132/132 [01:03<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.911      0.881      0.942      0.792      0.904      0.884      0.939      0.742\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      47/50      6.57G     0.8268      1.475     0.4691     0.9997         35        640: 100%|██████████| 132/132 [01:02<00:00,  2.11it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.907      0.894      0.945      0.799      0.909      0.889      0.941      0.743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      48/50      6.57G     0.8213      1.463     0.4634     0.9956         53        640: 100%|██████████| 132/132 [01:04<00:00,  2.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.923      0.879      0.946      0.801      0.919      0.878      0.941      0.748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      49/50      6.57G     0.8015      1.424     0.4518     0.9852         42        640: 100%|██████████| 132/132 [01:03<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.909      0.893      0.945        0.8      0.907      0.891      0.942      0.747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      50/50      6.57G     0.7989      1.421     0.4483     0.9856         55        640: 100%|██████████| 132/132 [01:03<00:00,  2.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.917      0.888      0.946      0.802       0.92      0.881      0.942      0.752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "50 epochs completed in 1.473 hours.\n",
            "Optimizer stripped from runs/segment/train/weights/last.pt, 23.9MB\n",
            "Optimizer stripped from runs/segment/train/weights/best.pt, 23.9MB\n",
            "\n",
            "Validating runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.116 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  25%|██▌       | 1/4 [00:00<00:02,  1.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|█████     | 2/4 [00:02<00:02,  1.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n",
            "WARNING ⚠️ Limiting validation plots to first 50 items per image for speed...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        105       2026      0.917      0.887      0.946      0.802       0.92      0.881      0.942      0.752\n",
            "Speed: 0.2ms preprocess, 7.4ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/train\u001b[0m\n",
            "Best model saved to /content/drive/MyDrive/FinalProject/models/best_rooftop.pt\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_rooftop_model(data_yaml_path, epochs=50, imgsz=640)\n",
        "model = YOLO('yolov8s-seg.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hZ9NdGaj2ZO",
        "outputId": "6ffb9e59-aa8f-45f3-bacb-b174e4228859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0Vnrh-snpD6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0201c8d3b2f04b329c0da1c0e239da3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158b131f247349249fb90b61be6186c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc560190e0649e4b245b61e0e124100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75515c9a4e794062b75faa289af3b075",
              "IPY_MODEL_9041dac2e0e6425ca5c3621500a46bce",
              "IPY_MODEL_575abbeeeba34c8598719b54949541a7",
              "IPY_MODEL_851ca58bfef44c419717698439fb59fc"
            ],
            "layout": "IPY_MODEL_dcb73f040aa445b79b57dbd89876f6b1"
          }
        },
        "575abbeeeba34c8598719b54949541a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Predict",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_a29bb2db37354836b22174acf380b35f",
            "style": "IPY_MODEL_f854dacab20d4caa8bcd8bd37fd2f2d5",
            "tooltip": "Click to run prediction"
          }
        },
        "75515c9a4e794062b75faa289af3b075": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c99e89e191b04411b9c4c9d5b0c38f6d",
            "placeholder": "​",
            "style": "IPY_MODEL_95622a92b71b453ca20ae4808fbb5e66",
            "value": "<h3>Rooftop Detection:</h3>"
          }
        },
        "851ca58bfef44c419717698439fb59fc": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_158b131f247349249fb90b61be6186c0",
            "msg_id": "051e44e8-74a3-4877-eb59-364c564739a4",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "Loading model...\n",
                  "Temporary files cleaned up\n",
                  "Please upload a JPG image:\n"
                ]
              },
              {
                "data": {
                  "text/html": "\n     <input type=\"file\" id=\"files-3031d292-69da-44b6-a3ce-10faa4a0e5bd\" name=\"files[]\" multiple disabled\n        style=\"border:none\" />\n     <output id=\"result-3031d292-69da-44b6-a3ce-10faa4a0e5bd\">\n      Upload widget is only available when the cell has been executed in the\n      current browser session. Please rerun this cell to enable.\n      </output>\n      <script>// Copyright 2017 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n/**\n * @fileoverview Helpers for google.colab Python module.\n */\n(function(scope) {\nfunction span(text, styleAttributes = {}) {\n  const element = document.createElement('span');\n  element.textContent = text;\n  for (const key of Object.keys(styleAttributes)) {\n    element.style[key] = styleAttributes[key];\n  }\n  return element;\n}\n\n// Max number of bytes which will be uploaded at a time.\nconst MAX_PAYLOAD_SIZE = 100 * 1024;\n\nfunction _uploadFiles(inputId, outputId) {\n  const steps = uploadFilesStep(inputId, outputId);\n  const outputElement = document.getElementById(outputId);\n  // Cache steps on the outputElement to make it available for the next call\n  // to uploadFilesContinue from Python.\n  outputElement.steps = steps;\n\n  return _uploadFilesContinue(outputId);\n}\n\n// This is roughly an async generator (not supported in the browser yet),\n// where there are multiple asynchronous steps and the Python side is going\n// to poll for completion of each step.\n// This uses a Promise to block the python side on completion of each step,\n// then passes the result of the previous step as the input to the next step.\nfunction _uploadFilesContinue(outputId) {\n  const outputElement = document.getElementById(outputId);\n  const steps = outputElement.steps;\n\n  const next = steps.next(outputElement.lastPromiseValue);\n  return Promise.resolve(next.value.promise).then((value) => {\n    // Cache the last promise value to make it available to the next\n    // step of the generator.\n    outputElement.lastPromiseValue = value;\n    return next.value.response;\n  });\n}\n\n/**\n * Generator function which is called between each async step of the upload\n * process.\n * @param {string} inputId Element ID of the input file picker element.\n * @param {string} outputId Element ID of the output display.\n * @return {!Iterable<!Object>} Iterable of next steps.\n */\nfunction* uploadFilesStep(inputId, outputId) {\n  const inputElement = document.getElementById(inputId);\n  inputElement.disabled = false;\n\n  const outputElement = document.getElementById(outputId);\n  outputElement.innerHTML = '';\n\n  const pickedPromise = new Promise((resolve) => {\n    inputElement.addEventListener('change', (e) => {\n      resolve(e.target.files);\n    });\n  });\n\n  const cancel = document.createElement('button');\n  inputElement.parentElement.appendChild(cancel);\n  cancel.textContent = 'Cancel upload';\n  const cancelPromise = new Promise((resolve) => {\n    cancel.onclick = () => {\n      resolve(null);\n    };\n  });\n\n  // Wait for the user to pick the files.\n  const files = yield {\n    promise: Promise.race([pickedPromise, cancelPromise]),\n    response: {\n      action: 'starting',\n    }\n  };\n\n  cancel.remove();\n\n  // Disable the input element since further picks are not allowed.\n  inputElement.disabled = true;\n\n  if (!files) {\n    return {\n      response: {\n        action: 'complete',\n      }\n    };\n  }\n\n  for (const file of files) {\n    const li = document.createElement('li');\n    li.append(span(file.name, {fontWeight: 'bold'}));\n    li.append(span(\n        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n        `last modified: ${\n            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n                                    'n/a'} - `));\n    const percent = span('0% done');\n    li.appendChild(percent);\n\n    outputElement.appendChild(li);\n\n    const fileDataPromise = new Promise((resolve) => {\n      const reader = new FileReader();\n      reader.onload = (e) => {\n        resolve(e.target.result);\n      };\n      reader.readAsArrayBuffer(file);\n    });\n    // Wait for the data to be ready.\n    let fileData = yield {\n      promise: fileDataPromise,\n      response: {\n        action: 'continue',\n      }\n    };\n\n    // Use a chunked sending to avoid message size limits. See b/62115660.\n    let position = 0;\n    do {\n      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n      const chunk = new Uint8Array(fileData, position, length);\n      position += length;\n\n      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n      yield {\n        response: {\n          action: 'append',\n          file: file.name,\n          data: base64,\n        },\n      };\n\n      let percentDone = fileData.byteLength === 0 ?\n          100 :\n          Math.round((position / fileData.byteLength) * 100);\n      percent.textContent = `${percentDone}% done`;\n\n    } while (position < fileData.byteLength);\n  }\n\n  // All done.\n  yield {\n    response: {\n      action: 'complete',\n    }\n  };\n}\n\nscope.google = scope.google || {};\nscope.google.colab = scope.google.colab || {};\nscope.google.colab._files = {\n  _uploadFiles,\n  _uploadFilesContinue,\n};\n})(self);\n</script> ",
                  "text/plain": "<IPython.core.display.HTML object>"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "9041dac2e0e6425ca5c3621500a46bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatSliderModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FloatSliderView",
            "continuous_update": false,
            "description": "Confidence:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0201c8d3b2f04b329c0da1c0e239da3b",
            "max": 1,
            "min": 0.1,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": ".2f",
            "step": 0.05,
            "style": "IPY_MODEL_b2e02833611f4b1291aa2c7c8043a3ab",
            "value": 0.2
          }
        },
        "95622a92b71b453ca20ae4808fbb5e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a29bb2db37354836b22174acf380b35f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e02833611f4b1291aa2c7c8043a3ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "SliderStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "c99e89e191b04411b9c4c9d5b0c38f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcb73f040aa445b79b57dbd89876f6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f854dacab20d4caa8bcd8bd37fd2f2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
